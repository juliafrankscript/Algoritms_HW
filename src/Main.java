public class Main {
    /* method1
   Если а=b, то выполнится 1 операция, соответственно, сложность в лучшем случае О(1).
   Если a>0 && b=1, то выполнится а операций, соответственно, сложность в худшем случае О(n).
    */
    void method1(int a, int b) {
        while (a != b) {
            if (a > b) {
                a = a - b;
            } else {
                b = b - a;
            }
        }
        System.out.println(a);
        System.out.println(b);
    }

    /* method2
        Цикл с i исполнится n/2 раз.
        На каждое исполнение цикла i, цикл j исполнится также n/2 раз. (Условие j + n / 2 <= n равносильно j <= n/2).
        На каждое исполнение цикла j, цикл k исполнится около log_2(n) раз.
        Итого: общее число исполнений это n/2 * n/2 * log_2(n). Соответственно, временная сложность О(n^2 * log(n)).
     */
    void method2(int n) {
        for (int i = 0; i < n / 2; i++) {
            for (int j = 1; j + n / 2 <= n; j++) {
                for (int k = 1; k <= n; k = k * 2) {
                    System.out.println("I am expert!");
                }
            }
        }
    }

    /* method3
        Число операций в данных циклах будет таким: n + n/2 + n/3 + ... + n/(n-1) + n/n.
        Можем представить это в виде n*(1 + 1/2 + 1/3 + ... + 1/(n-1) + 1/n). Часть в скобках - это гармонический ряд.
        Сумма первых n членов гармонического ряда равна ln(n) + y + e_n, таким образом, число операций
        равняется n*ln(n) + n*y + n*e_n. Поскольку для временной сложности нам нужны только слагаемые высшего порядка,
        и с учетом того, что логарифмы растут с одинаковой скоростью, имеем временную сложность O(n*log(n)).
     */
    void method3(int n) {
        for (int i = 1; i <= n; i++) {
            for (int j = 1; j <= n; j = j + i) {
                System.out.println("I am expert!");
            }
        }
    }
}